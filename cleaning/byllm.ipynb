{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be010da",
   "metadata": {},
   "source": [
    "## byLLM Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb8d97c",
   "metadata": {},
   "source": [
    "Description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c358efb3-222f-4c1f-a5c1-c12eef925c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f27e80-dc6f-46df-a82d-4583b5ec6a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing API Key! Please set the LLM_API_KEY environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m apiKey = os.getenv(\u001b[33m'\u001b[39m\u001b[33mLLM_API_KEY\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m apiKey:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMissing API Key! Please set the LLM_API_KEY environment variable.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Use the key in your LLM call\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# client = OpenAI(api_key=api_key)\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Missing API Key! Please set the LLM_API_KEY environment variable."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# This pulls the value from the system variable\n",
    "apiKey = os.getenv('LLM_API_KEY')\n",
    "\n",
    "if not apiKey:\n",
    "    raise ValueError(\"Missing API Key! Please set the LLM_API_KEY environment variable.\")\n",
    "\n",
    "# Use the key in your LLM call\n",
    "# client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf5aed0-7dd3-4775-8e55-f586bbf1b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from byllm.lib import Model, by\n",
    "llm = Model(model_name=\"gemini/gemini-2.5-flash\" , api_key= apiKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92bbac1e-3fec-48c2-932b-54a0d7d2da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = '../data/fdic/fdic_250.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0357d79-4e57-427d-821c-5c37c5770fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb1dd530-0677-44cf-986d-46d143920882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      fdic_certificate_number              institution_name    state_name  \\\n",
       "0                       8870  BankFirst Financial Services   Mississippi   \n",
       "1                      11423                 Sycamore Bank   Mississippi   \n",
       "2                       9120            Rolette State Bank  North Dakota   \n",
       "3                       3914          Ramsey National Bank  North Dakota   \n",
       "4                      28679              North Shore Bank     Wisconsin   \n",
       "..                       ...                           ...           ...   \n",
       "245                    19904         Centinel Bank of Taos    New Mexico   \n",
       "246                      109            Horatio State Bank      Arkansas   \n",
       "247                    16600              First State Bank    New Mexico   \n",
       "248                    28362                  Century Bank    New Mexico   \n",
       "249                    14904          First Community Bank          Iowa   \n",
       "\n",
       "     fdic_id  docket  active                   address  total_assets  \\\n",
       "0       5663   10529    True               900 Main St     2045233.0   \n",
       "1       7294       0   False             301 E Main St      329170.0   \n",
       "2       5838       0    True           209 Main Street       51045.0   \n",
       "3       2551   12753   False             300 4th St Ne      319992.0   \n",
       "4      41513    2130    True      15700 W Bluemound Rd     2617053.0   \n",
       "..       ...     ...     ...                       ...           ...   \n",
       "245    13679   10688    True  512 Paseo Del Pueblo Sur      386069.0   \n",
       "246       88       0    True             123 W Main St      250455.0   \n",
       "247    10743       0    True      103 Manzanares Ave E      187021.0   \n",
       "248    41196    1441    True          100 S Federal Pl     1235526.0   \n",
       "249     9333       0    True           119 S Fulton St      118433.0   \n",
       "\n",
       "    bank_charter_class  change_code_1  ...  \\\n",
       "0                   SM          810.0  ...   \n",
       "1                   NM          223.0  ...   \n",
       "2                   NM            NaN  ...   \n",
       "3                    N          223.0  ...   \n",
       "4                   SI          510.0  ...   \n",
       "..                 ...            ...  ...   \n",
       "245                 NM            NaN  ...   \n",
       "246                 NM            NaN  ...   \n",
       "247                 NM            NaN  ...   \n",
       "248                 NM            NaN  ...   \n",
       "249                 NM            NaN  ...   \n",
       "\n",
       "                               csa_name  csa_fips_code  csa_indicator  \\\n",
       "0               Columbus-West Point, MS          200.0           True   \n",
       "1        Memphis-Forrest City, TN-MS-AR          368.0           True   \n",
       "2                                   NaN            NaN            NaN   \n",
       "3                                   NaN            NaN            NaN   \n",
       "4         Milwaukee-Racine-Waukesha, WI          376.0           True   \n",
       "..                                  ...            ...            ...   \n",
       "245                                 NaN            NaN          False   \n",
       "246                                 NaN            NaN            NaN   \n",
       "247                                 NaN            NaN            NaN   \n",
       "248  Albuquerque-Santa Fe-Las Vegas, NM          106.0           True   \n",
       "249                                 NaN            NaN          False   \n",
       "\n",
       "                  cbsa_name  cbsa_fips_code  cbsa_metro_flag  cbsa_micro_flag  \\\n",
       "0              Columbus, MS         18060.0            False             True   \n",
       "1         Memphis, TN-MS-AR         32820.0             True            False   \n",
       "2                       NaN             NaN              NaN              NaN   \n",
       "3                       NaN             NaN              NaN              NaN   \n",
       "4    Milwaukee-Waukesha, WI         33340.0             True            False   \n",
       "..                      ...             ...              ...              ...   \n",
       "245                Taos, NM         45340.0            False             True   \n",
       "246                     NaN             NaN              NaN              NaN   \n",
       "247                     NaN             NaN              NaN              NaN   \n",
       "248            Santa Fe, NM         42140.0             True            False   \n",
       "249          Storm Lake, IA         44740.0            False             True   \n",
       "\n",
       "     cbsa_division_name  cbsa_division_fips_code  cbsa_division_flag  \n",
       "0                   NaN                      NaN               False  \n",
       "1                   NaN                      NaN               False  \n",
       "2                   NaN                      NaN                 NaN  \n",
       "3                   NaN                      NaN                 NaN  \n",
       "4                   NaN                      NaN               False  \n",
       "..                  ...                      ...                 ...  \n",
       "245                 NaN                      NaN               False  \n",
       "246                 NaN                      NaN                 NaN  \n",
       "247                 NaN                      NaN                 NaN  \n",
       "248                 NaN                      NaN               False  \n",
       "249                 NaN                      NaN               False  \n",
       "\n",
       "[250 rows x 121 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d216e0de-2124-4474-9a3a-11ff5fede64e",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Unterminated string starting at: line 1 column 199317 (char 199316)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_df\n\u001b[32m     21\u001b[39m records = df.astype(\u001b[38;5;28mstr\u001b[39m).to_dict(orient=\u001b[33m'\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m cleaned_records = \u001b[43mclean_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# cleaned_df = clean_dataframe(df)\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# print(cleaned_df)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\byllm/plugin.jac:98\u001b[39m, in \u001b[36m_wrapped_caller\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m         ir_info=fetch_mtir(caller)\n\u001b[32m     97\u001b[39m     ).runtime;\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     return model.invoke(mt_run=mtir);\n\u001b[32m     99\u001b[39m }\n\u001b[32m    100\u001b[39m return _wrapped_caller;\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/runner/work/jaseci/jaseci/jac-byllm/byllm/llm.impl/model.impl.jac:35\u001b[39m, in \u001b[36minvoke\u001b[39m\u001b[34m(self, mt_run)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/runner/work/jaseci/jaseci/jac-byllm/byllm/llm.impl/basellm.impl.jac:50\u001b[39m, in \u001b[36minvoke\u001b[39m\u001b[34m(self, mt_run)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/runner/work/jaseci/jaseci/jac-byllm/byllm/llm.impl/basellm.impl.jac:171\u001b[39m, in \u001b[36mdispatch_no_streaming\u001b[39m\u001b[34m(self, mt_run)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/runner/work/jaseci/jaseci/jac-byllm/byllm/impl/mtir.impl.jac:216\u001b[39m, in \u001b[36mparse_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\json\\decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     end = _w(s, end).end()\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\json\\decoder.py:354\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    347\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Unterminated string starting at: line 1 column 199317 (char 199316)"
     ]
    }
   ],
   "source": [
    "@by(llm)\n",
    "def clean_records(records: list[dict[str, str]]) -> list[dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Clean a list of records represented as dictionaries.\n",
    "    Each record has string fields which should be trimmed and validated.\n",
    "    Returns the cleaned list of records.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Convert DataFrame to list of dicts with string keys and string values\n",
    "    # Use astype(str) to convert all values to strings to match typing\n",
    "    records = df.astype(str).to_dict(orient='records')\n",
    "    # Call the LLM-powered cleaning function\n",
    "    cleaned_records = clean_records(records)\n",
    "    # Convert cleaned records back to DataFrame\n",
    "    cleaned_df = pd.DataFrame(cleaned_records)\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "records = df.astype(str).to_dict(orient='records')\n",
    "cleaned_records = clean_records(records)\n",
    "    \n",
    "# cleaned_df = clean_dataframe(df)\n",
    "# print(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3deacfcc-d44d-428d-b4e2-ca5640295f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "litellm.BadRequestError: GeminiException BadRequestError - {\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"Your API key was reported as leaked. Please use another API key.\",\n    \"status\": \"PERMISSION_DENIED\"\n  }\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\litellm\\llms\\vertex_ai\\gemini\\vertex_and_google_ai_studio_gemini.py:2241\u001b[39m, in \u001b[36mVertexLLM.completion\u001b[39m\u001b[34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[39m\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   2242\u001b[39m     response.raise_for_status()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\http_handler.py:898\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mstatus_code\u001b[39m\u001b[33m\"\u001b[39m, e.response.status_code)\n\u001b[32m--> \u001b[39m\u001b[32m898\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\http_handler.py:880\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    879\u001b[39m response = \u001b[38;5;28mself\u001b[39m.client.send(req, stream=stream)\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '403 Forbidden' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=AIzaSyCoDP6wa0g4UkgJue3nZqDDHoLQG_nPv9E'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mVertexAIError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\litellm\\main.py:2871\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   2870\u001b[39m     new_params = safe_deep_copy(optional_params \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[32m-> \u001b[39m\u001b[32m2871\u001b[39m     response = \u001b[43mvertex_chat_completion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2876\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2878\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_ai_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgemini_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgemini_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2885\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2886\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2887\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2888\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2889\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2890\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2891\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2893\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mvertex_ai\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\litellm\\llms\\vertex_ai\\gemini\\vertex_and_google_ai_studio_gemini.py:2245\u001b[39m, in \u001b[36mVertexLLM.completion\u001b[39m\u001b[34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[39m\n\u001b[32m   2244\u001b[39m     error_code = err.response.status_code\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m VertexAIError(\n\u001b[32m   2246\u001b[39m         status_code=error_code,\n\u001b[32m   2247\u001b[39m         message=err.response.text,\n\u001b[32m   2248\u001b[39m         headers=err.response.headers,\n\u001b[32m   2249\u001b[39m     )\n\u001b[32m   2250\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException:\n",
      "\u001b[31mVertexAIError\u001b[39m: {\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"Your API key was reported as leaked. Please use another API key.\",\n    \"status\": \"PERMISSION_DENIED\"\n  }\n}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m cleaned_records = []\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m batch(records, \u001b[32m20\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     cleaned_chunk = \u001b[43mclean_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Your LLM function\u001b[39;00m\n\u001b[32m     29\u001b[39m     cleaned_records.extend(cleaned_chunk)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# cleaned_df = clean_dataframe(df)\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# print(cleaned_df)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\byllm/plugin.jac:98\u001b[39m, in \u001b[36m_wrapped_caller\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m         ir_info=fetch_mtir(caller)\n\u001b[32m     97\u001b[39m     ).runtime;\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     return model.invoke(mt_run=mtir);\n\u001b[32m     99\u001b[39m }\n\u001b[32m    100\u001b[39m return _wrapped_caller;\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/runner/work/jaseci/jaseci/jac-byllm/byllm/llm.impl/model.impl.jac:35\u001b[39m, in \u001b[36minvoke\u001b[39m\u001b[34m(self, mt_run)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/runner/work/jaseci/jaseci/jac-byllm/byllm/llm.impl/basellm.impl.jac:50\u001b[39m, in \u001b[36minvoke\u001b[39m\u001b[34m(self, mt_run)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/runner/work/jaseci/jaseci/jac-byllm/byllm/llm.impl/basellm.impl.jac:162\u001b[39m, in \u001b[36mdispatch_no_streaming\u001b[39m\u001b[34m(self, mt_run)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/runner/work/jaseci/jaseci/jac-byllm/byllm/llm.impl/model.impl.jac:55\u001b[39m, in \u001b[36mmodel_call_no_stream\u001b[39m\u001b[34m(self, params)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\litellm\\utils.py:1377\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1374\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1375\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1376\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1377\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\litellm\\utils.py:1246\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1244\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1245\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1247\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[32m   1249\u001b[39m     kwargs=kwargs,\n\u001b[32m   1250\u001b[39m     call_type=call_type,\n\u001b[32m   1251\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\litellm\\main.py:3770\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   3767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   3768\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3769\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3770\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3771\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3772\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3773\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3774\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3775\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3776\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:2323\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2322\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2323\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2325\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\my_env\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:1274\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   1272\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m403\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str:\n\u001b[32m   1273\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n\u001b[32m   1275\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcustom_llm_provider.capitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mException BadRequestError - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1276\u001b[39m         model=model,\n\u001b[32m   1277\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m   1278\u001b[39m         response=httpx.Response(\n\u001b[32m   1279\u001b[39m             status_code=\u001b[32m403\u001b[39m,\n\u001b[32m   1280\u001b[39m             request=httpx.Request(\n\u001b[32m   1281\u001b[39m                 method=\u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1282\u001b[39m                 url=\u001b[33m\"\u001b[39m\u001b[33m https://cloud.google.com/vertex-ai/\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1283\u001b[39m             ),\n\u001b[32m   1284\u001b[39m         ),\n\u001b[32m   1285\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m   1286\u001b[39m     )\n\u001b[32m   1287\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   1288\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThe response was blocked.\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[32m   1289\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mOutput blocked by content filtering policy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1290\u001b[39m     \u001b[38;5;129;01min\u001b[39;00m error_str  \u001b[38;5;66;03m# anthropic on vertex ai\u001b[39;00m\n\u001b[32m   1291\u001b[39m ):\n\u001b[32m   1292\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mBadRequestError\u001b[39m: litellm.BadRequestError: GeminiException BadRequestError - {\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"Your API key was reported as leaked. Please use another API key.\",\n    \"status\": \"PERMISSION_DENIED\"\n  }\n}\n"
     ]
    }
   ],
   "source": [
    "@by(llm)\n",
    "def clean_list(records: list[dict[str, str]]) -> list[dict[str, str]]: ...\n",
    "\n",
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Convert DataFrame to list of dicts with string keys and string values\n",
    "    # Use astype(str) to convert all values to strings to match typing\n",
    "    records = df.astype(str).to_dict(orient='records')\n",
    "    # Call the LLM-powered cleaning function\n",
    "    cleaned_records = clean_records(records)\n",
    "    # Convert cleaned records back to DataFrame\n",
    "    cleaned_df = pd.DataFrame(cleaned_records)\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "records = df.astype(str).to_dict(orient='records')\n",
    "\n",
    "\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "# Process in chunks of 20\n",
    "cleaned_records = []\n",
    "for chunk in batch(records, 20):\n",
    "    cleaned_chunk = clean_records(chunk) # Your LLM function\n",
    "    cleaned_records.extend(cleaned_chunk)\n",
    "\n",
    "    \n",
    "# cleaned_df = clean_dataframe(df)\n",
    "# print(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc52e6-d5b0-4376-b735-2ef337cacbeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
